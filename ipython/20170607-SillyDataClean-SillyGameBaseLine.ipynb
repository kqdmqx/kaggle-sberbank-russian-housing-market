{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess (train_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad_life_sq 815\n",
      "bad_full_sq 36\n",
      "bad_kitch_sq 8417\n",
      "bad_build_year 1463\n",
      "bad_num_room 23\n",
      "bad_floor 2145\n",
      "max_floor 2140\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "train = pd.read_csv(\"../input/train.csv\", parse_dates=['timestamp'])\n",
    "test = pd.read_csv(\"../input/test.csv\", parse_dates=['timestamp'])\n",
    "\n",
    "train_id = train.id\n",
    "test_id = test.id\n",
    "train_columns = train.columns.tolist()\n",
    "test_columns = test.columns.tolist()\n",
    "\n",
    "\n",
    "def tridx(col):\n",
    "    if col not in train_columns:\n",
    "        return -1\n",
    "    return train_columns.index(col)\n",
    "\n",
    "def tsidx(col):\n",
    "    if col not in test_columns:\n",
    "        return -1\n",
    "    return test_columns.index(col)\n",
    "\n",
    "# 纠正个别错误\n",
    "# @life_sq\n",
    "equal_index = [601, 1896, 2791]\n",
    "test.iloc[equal_index, tsidx('life_sq')] = test.iloc[equal_index, tsidx('full_sq')]\n",
    "\n",
    "# @build_year\n",
    "kitch_is_build_year = [13117]\n",
    "train.iloc[kitch_is_build_year, tridx('build_year')] = train.iloc[kitch_is_build_year, tridx('kitch_sq')]\n",
    "\n",
    "# @state\n",
    "train.loc[train.state == 33, 'state'] = np.NaN\n",
    "\n",
    "# process bad index, fill with nan\n",
    "train_test = pd.concat([train, test])\n",
    "is_train = train_test.id.isin(train_id.unique())\n",
    "is_test = train_test.id.isin(test_id.unique())\n",
    "\n",
    "# 标记离群点\n",
    "# @life_sq\n",
    "isbad_life_sq = ((train_test.life_sq > train_test.full_sq) | \n",
    "                 (train_test.life_sq < 5) |\n",
    "                 ((train_test.life_sq > 300) & is_train) |\n",
    "                 ((train_test.life_sq > 200) & is_test))\n",
    "isbad_life_sq_id = train_test.loc[isbad_life_sq, 'id']\n",
    "train_test.loc[isbad_life_sq, 'life_sq'] = np.NaN\n",
    "print 'bad_life_sq', np.sum(isbad_life_sq)\n",
    "\n",
    "# @full_sq\n",
    "isbad_full_sq = ((train_test.full_sq < 5) |\n",
    "                 ((train_test.full_sq > 210) & (train_test.life_sq / train_test.full_sq < 0.3) & is_train) |\n",
    "                 ((train_test.full_sq > 150) & (train_test.life_sq / train_test.full_sq < 0.3) & is_test) |\n",
    "                 ((train_test.life_sq > 300) & is_train) |\n",
    "                 ((train_test.life_sq > 200) & is_test))\n",
    "isbad_full_sq_id = train_test.loc[isbad_full_sq, 'id']\n",
    "train_test.loc[isbad_full_sq, 'full_sq'] = np.NaN\n",
    "print 'bad_full_sq', np.sum(isbad_full_sq)\n",
    "\n",
    "# @kitch_sq\n",
    "isbad_kitch_sq = ((train_test.id == 13120) |\n",
    "                  (train_test.kitch_sq > train_test.life_sq) |\n",
    "                  (train_test.kitch_sq == 0) |\n",
    "                  (train_test.kitch_sq == 1))\n",
    "isbad_kitch_sq_id = train_test.loc[isbad_kitch_sq, 'id']\n",
    "train_test.loc[isbad_kitch_sq, 'kitch_sq'] = np.NaN\n",
    "print 'bad_kitch_sq', np.sum(isbad_kitch_sq)\n",
    "\n",
    "# @build_year\n",
    "isbad_build_year = ((train_test.build_year < 1500) |\n",
    "                    (train_test.build_year > 2200))\n",
    "isbad_build_year_id = train_test.loc[isbad_build_year, 'id']\n",
    "train_test.loc[isbad_build_year, 'build_year'] = np.NaN\n",
    "print 'bad_build_year', np.sum(isbad_build_year)\n",
    "\n",
    "# @num_room\n",
    "isbad_num_room_selected_id = train_test.iloc[[10076, 11621, 17764, 19390, 24007, 26713, 29172, 3174, 7313]].id.unique()\n",
    "isbad_num_room = ((train_test.id.isin(isbad_num_room_selected_id)) |\n",
    "                  (train_test.num_room == 0))\n",
    "isbad_num_room_id = train_test.loc[isbad_num_room, 'id']\n",
    "train_test.loc[isbad_num_room, 'num_room'] = np.NaN\n",
    "print 'bad_num_room', np.sum(isbad_num_room)\n",
    "\n",
    "# @floor\n",
    "isbad_floor = ((train_test.floor > train_test.max_floor)|\n",
    "               (train_test.floor == 0))\n",
    "isbad_floor_id = train_test.loc[isbad_floor, 'id']\n",
    "train_test.loc[isbad_floor, 'num_room'] = np.NaN\n",
    "print 'bad_floor', np.sum(isbad_floor)\n",
    "\n",
    "# @max_floor\n",
    "isbad_max_floor = ((train_test.floor > train_test.max_floor)|\n",
    "                   (train_test.max_floor == 0))\n",
    "isbad_max_floor_id = train_test.loc[isbad_max_floor, 'id']\n",
    "train_test.loc[isbad_max_floor, 'num_room'] = np.NaN\n",
    "print 'max_floor', np.sum(isbad_max_floor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_test additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add month-year\n",
    "train_test['month_year_cnt'] = train_test.timestamp.dt.year * 100 + train_test.timestamp.dt.month\n",
    "\n",
    "# Add week-year count\n",
    "train_test['week_year_cnt'] = train_test.timestamp.dt.year * 100 + train_test.timestamp.dt.weekofyear\n",
    "\n",
    "# Add month and day-of-week\n",
    "train_test['month'] = train_test.timestamp.dt.month\n",
    "train_test['dow'] = train_test.timestamp.dt.dayofweek\n",
    "\n",
    "# Other feature engineering\n",
    "train_test['rel_floor'] = train_test['floor'] / train_test['max_floor'].astype(float)\n",
    "train_test['rel_kitch_sq'] = train_test['kitch_sq'] / train_test['full_sq'].astype(float)\n",
    "\n",
    "train_test.apartment_name=train_test.sub_area + train_test['metro_km_avto'].astype(str)\n",
    "train_test['room_size'] = train_test['life_sq'] / train_test['num_room'].astype(float)\n",
    "\n",
    "# Deal with categorical values\n",
    "train_test_numeric = train_test.select_dtypes(exclude=['object'])\n",
    "train_test_obj = train_test.select_dtypes(include=['object']).copy()\n",
    "\n",
    "for c in train_test_obj:\n",
    "    train_test_obj[c] = pd.factorize(train_test_obj[c])[0]\n",
    "\n",
    "train_test_values = pd.concat([train_test_numeric, train_test_obj], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_clean & train_ex (target outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_outlier 41\n"
     ]
    }
   ],
   "source": [
    "train = train_test_values.loc[train_test_values.id.isin(train_id.unique())]\n",
    "test = train_test_values.loc[train_test_values.id.isin(test_id.unique())]\n",
    "\n",
    "train_outlier = ((train.price_doc/train.full_sq > 600000) |\n",
    "                 (train.price_doc/train.full_sq < 10000))\n",
    "train_outlier_id = train.loc[train_outlier].id\n",
    "print 'train_outlier', np.sum(train_outlier)\n",
    "\n",
    "train_clean = train.loc[~train_outlier].copy()\n",
    "train_clean_id = train_clean['id']\n",
    "test = test['id']\n",
    "train_ex = train.loc[train_outlier].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# single xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30474</td>\n",
       "      <td>5675442.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30475</td>\n",
       "      <td>8293440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30476</td>\n",
       "      <td>5553692.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30477</td>\n",
       "      <td>5731263.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30478</td>\n",
       "      <td>5321836.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  price_doc\n",
       "0  30474  5675442.0\n",
       "1  30475  8293440.0\n",
       "2  30476  5553692.0\n",
       "3  30477  5731263.0\n",
       "4  30478  5321836.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train_clean[\"price_doc\"]\n",
    "x_train = train_clean.drop([\"id\", \"timestamp\", \"price_doc\"], axis=1)\n",
    "x_test = test.drop([\"id\", \"timestamp\", \"price_doc\"], axis=1)\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'silent': 0,\n",
    "    'booster' :'gbtree',\n",
    "    'tuneLength': 3\n",
    "}\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, y_train)\n",
    "dtest = xgb.DMatrix(x_test)\n",
    "\n",
    "#cv_output = xgb.cv(xgb_params, dtrain, num_boost_round=1000, early_stopping_rounds=20,\n",
    "#    verbose_eval=50, show_stdv=False)\n",
    "#cv_output[['train-rmse-mean', 'test-rmse-mean']].plot()\n",
    "\n",
    "#num_boost_rounds = len(cv_output)\n",
    "model = xgb.train(dict(xgb_params, silent=1), dtrain, num_boost_round=300)\n",
    "\n",
    "#fig, ax = plt.subplots(1, 1, figsize=(8, 13))\n",
    "#xgb.plot_importance(model, max_num_features=50, height=0.5, ax=ax)\n",
    "\n",
    "y_predict = model.predict(dtest)\n",
    "y_predict = np.round(y_predict * 0.99)\n",
    "gunja_output = pd.DataFrame({'id': test_id, 'price_doc': y_predict})\n",
    "gunja_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gunja_output.to_csv('../output/Submission-SillyDataBaseLine-GunJa.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stacking2 baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tval-rmse:8.29106e+06\n",
      "Will train until val-rmse hasn't improved in 25 rounds.\n",
      "[25]\tval-rmse:3.7861e+06\n",
      "[50]\tval-rmse:2.95184e+06\n",
      "[75]\tval-rmse:2.79838e+06\n",
      "[100]\tval-rmse:2.7385e+06\n",
      "[125]\tval-rmse:2.70543e+06\n",
      "[150]\tval-rmse:2.686e+06\n",
      "[175]\tval-rmse:2.6703e+06\n",
      "[200]\tval-rmse:2.66033e+06\n",
      "[225]\tval-rmse:2.65209e+06\n",
      "[250]\tval-rmse:2.65038e+06\n",
      "[275]\tval-rmse:2.64542e+06\n",
      "[300]\tval-rmse:2.64446e+06\n",
      "[325]\tval-rmse:2.64193e+06\n",
      "[350]\tval-rmse:2.63908e+06\n",
      "Stopping. Best iteration:\n",
      "[342]\tval-rmse:2.63846e+06\n",
      "\n",
      "[0]\tval-rmse:8.09555e+06\n",
      "Will train until val-rmse hasn't improved in 25 rounds.\n",
      "[25]\tval-rmse:3.55204e+06\n",
      "[50]\tval-rmse:2.80191e+06\n",
      "[75]\tval-rmse:2.69531e+06\n",
      "[100]\tval-rmse:2.65559e+06\n",
      "[125]\tval-rmse:2.63978e+06\n",
      "[150]\tval-rmse:2.62435e+06\n",
      "[175]\tval-rmse:2.61188e+06\n",
      "[200]\tval-rmse:2.6009e+06\n",
      "[225]\tval-rmse:2.59753e+06\n",
      "[250]\tval-rmse:2.58624e+06\n",
      "[275]\tval-rmse:2.58284e+06\n",
      "[300]\tval-rmse:2.5815e+06\n",
      "Stopping. Best iteration:\n",
      "[289]\tval-rmse:2.58041e+06\n",
      "\n",
      "[0]\tval-rmse:8.18602e+06\n",
      "Will train until val-rmse hasn't improved in 25 rounds.\n",
      "[25]\tval-rmse:3.62754e+06\n",
      "[50]\tval-rmse:2.82481e+06\n",
      "[75]\tval-rmse:2.68665e+06\n",
      "[100]\tval-rmse:2.64907e+06\n",
      "[125]\tval-rmse:2.62633e+06\n",
      "[150]\tval-rmse:2.61064e+06\n",
      "[175]\tval-rmse:2.60003e+06\n",
      "[200]\tval-rmse:2.58696e+06\n",
      "[225]\tval-rmse:2.58054e+06\n",
      "[250]\tval-rmse:2.57103e+06\n",
      "[275]\tval-rmse:2.56737e+06\n",
      "[300]\tval-rmse:2.56184e+06\n",
      "[325]\tval-rmse:2.55554e+06\n",
      "[350]\tval-rmse:2.55286e+06\n",
      "[375]\tval-rmse:2.54909e+06\n",
      "[400]\tval-rmse:2.55157e+06\n",
      "Stopping. Best iteration:\n",
      "[376]\tval-rmse:2.54841e+06\n",
      "\n",
      "[0]\tval-rmse:8.00087e+06\n",
      "Will train until val-rmse hasn't improved in 25 rounds.\n",
      "[25]\tval-rmse:3.51523e+06\n",
      "[50]\tval-rmse:2.76656e+06\n",
      "[75]\tval-rmse:2.66448e+06\n",
      "[100]\tval-rmse:2.63899e+06\n",
      "[125]\tval-rmse:2.62112e+06\n",
      "[150]\tval-rmse:2.6118e+06\n",
      "[175]\tval-rmse:2.60279e+06\n",
      "[200]\tval-rmse:2.59569e+06\n",
      "[225]\tval-rmse:2.587e+06\n",
      "[250]\tval-rmse:2.58302e+06\n",
      "[275]\tval-rmse:2.57947e+06\n",
      "[300]\tval-rmse:2.57739e+06\n",
      "[325]\tval-rmse:2.57588e+06\n",
      "Stopping. Best iteration:\n",
      "[322]\tval-rmse:2.57446e+06\n",
      "\n",
      "[0]\tval-rmse:8.1234e+06\n",
      "Will train until val-rmse hasn't improved in 25 rounds.\n",
      "[25]\tval-rmse:3.57045e+06\n",
      "[50]\tval-rmse:2.72754e+06\n",
      "[75]\tval-rmse:2.58556e+06\n",
      "[100]\tval-rmse:2.54371e+06\n",
      "[125]\tval-rmse:2.51764e+06\n",
      "[150]\tval-rmse:2.4974e+06\n",
      "[175]\tval-rmse:2.48638e+06\n",
      "[200]\tval-rmse:2.47328e+06\n",
      "[225]\tval-rmse:2.46701e+06\n",
      "[250]\tval-rmse:2.46381e+06\n",
      "[275]\tval-rmse:2.45874e+06\n",
      "[300]\tval-rmse:2.45613e+06\n",
      "[325]\tval-rmse:2.45391e+06\n",
      "[350]\tval-rmse:2.45344e+06\n",
      "Stopping. Best iteration:\n",
      "[342]\tval-rmse:2.45244e+06\n",
      "\n",
      "0.457671503887\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'id_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-0d45445b92b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_oof_single\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m \u001b[0mdf_sub\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mid_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'price_doc'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpred_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[0mdf_sub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../output/stacking/Submission-SillyDataBaseLine-GunJa-Stacking2-2017060700-Test.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'id_test' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from my_py_models.stacking import Stacking\n",
    "from my_py_models.my_xgb_classifier import MyXgbClassifier\n",
    "from my_py_models.my_xgb_classifier2 import MyXgbClassifier2\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_train = train_clean[\"price_doc\"]\n",
    "x_train = train_clean.drop([\"id\", \"timestamp\", \"price_doc\"], axis=1)\n",
    "x_test = test.drop([\"id\", \"timestamp\", \"price_doc\"], axis=1)\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'silent': 0,\n",
    "    'booster' :'gbtree',\n",
    "    'tuneLength': 3\n",
    "}\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, y_train)\n",
    "dtest = xgb.DMatrix(x_test)\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'silent': 0,\n",
    "    'booster' :'gbtree',\n",
    "    'tuneLength': 3\n",
    "}\n",
    "\n",
    "clf = MyXgbClassifier2(xgb_params)\n",
    "stacking = Stacking(5, [clf])\n",
    "pred_oof, pred_test = stacking.fit_predict(x_train, y_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.457671503887\n"
     ]
    }
   ],
   "source": [
    "for pred_oof_single in pred_oof.T:\n",
    "    print np.sqrt(mean_squared_error(np.log(pred_oof_single + 1), np.log(y_train + 1)))\n",
    "\n",
    "df_sub = pd.DataFrame({'id': test_id, 'price_doc': pred_test[:, 0]})\n",
    "df_sub.to_csv('../output/stacking/Submission-SillyDataBaseLine-GunJa-Stacking2-2017060700-Test.csv', index=False)\n",
    "\n",
    "df_oof = pd.DataFrame({'id': train_clean_id, 'price_doc': pred_oof[:, 0]})\n",
    "df_oof.to_csv('../output/stacking/Submission-SillyDataBaseLine-GunJa-Stacking2-20170606700-OutOfFold-ToBeFixed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess (macro)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "nav_menu": {
    "height": "84px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "908px",
    "left": "0px",
    "right": "708px",
    "top": "106px",
    "width": "336px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
