{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess (train_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_test (feature outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad_life_sq 815\n",
      "bad_full_sq 36\n",
      "bad_kitch_sq 8417\n",
      "bad_build_year 1463\n",
      "bad_num_room 23\n",
      "bad_floor 2145\n",
      "max_floor 2140\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "train = pd.read_csv(\"../input/train.csv\", parse_dates=['timestamp'])\n",
    "test = pd.read_csv(\"../input/test.csv\", parse_dates=['timestamp'])\n",
    "\n",
    "train_id = train.id\n",
    "test_id = test.id\n",
    "train_columns = train.columns.tolist()\n",
    "test_columns = test.columns.tolist()\n",
    "\n",
    "\n",
    "def tridx(col):\n",
    "    if col not in train_columns:\n",
    "        return -1\n",
    "    return train_columns.index(col)\n",
    "\n",
    "def tsidx(col):\n",
    "    if col not in test_columns:\n",
    "        return -1\n",
    "    return test_columns.index(col)\n",
    "\n",
    "# 纠正个别错误\n",
    "# @life_sq\n",
    "equal_index = [601, 1896, 2791]\n",
    "test.iloc[equal_index, tsidx('life_sq')] = test.iloc[equal_index, tsidx('full_sq')]\n",
    "\n",
    "# @build_year\n",
    "kitch_is_build_year = [13117]\n",
    "train.iloc[kitch_is_build_year, tridx('build_year')] = train.iloc[kitch_is_build_year, tridx('kitch_sq')]\n",
    "\n",
    "# @state\n",
    "train.loc[train.state == 33, 'state'] = np.NaN\n",
    "\n",
    "# process bad index, fill with nan\n",
    "train_test = pd.concat([train, test])\n",
    "is_train = train_test.id.isin(train_id.unique())\n",
    "is_test = train_test.id.isin(test_id.unique())\n",
    "\n",
    "# 标记离群点\n",
    "# @life_sq\n",
    "isbad_life_sq = ((train_test.life_sq > train_test.full_sq) | \n",
    "                 (train_test.life_sq < 5) |\n",
    "                 ((train_test.life_sq > 300) & is_train) |\n",
    "                 ((train_test.life_sq > 200) & is_test))\n",
    "isbad_life_sq_id = train_test.loc[isbad_life_sq, 'id']\n",
    "train_test.loc[isbad_life_sq, 'life_sq'] = np.NaN\n",
    "print 'bad_life_sq', np.sum(isbad_life_sq)\n",
    "\n",
    "# @full_sq\n",
    "isbad_full_sq = ((train_test.full_sq < 5) |\n",
    "                 ((train_test.full_sq > 210) & (train_test.life_sq / train_test.full_sq < 0.3) & is_train) |\n",
    "                 ((train_test.full_sq > 150) & (train_test.life_sq / train_test.full_sq < 0.3) & is_test) |\n",
    "                 ((train_test.life_sq > 300) & is_train) |\n",
    "                 ((train_test.life_sq > 200) & is_test))\n",
    "isbad_full_sq_id = train_test.loc[isbad_full_sq, 'id']\n",
    "train_test.loc[isbad_full_sq, 'full_sq'] = np.NaN\n",
    "print 'bad_full_sq', np.sum(isbad_full_sq)\n",
    "\n",
    "# @kitch_sq\n",
    "isbad_kitch_sq = ((train_test.id == 13120) |\n",
    "                  (train_test.kitch_sq > train_test.life_sq) |\n",
    "                  (train_test.kitch_sq == 0) |\n",
    "                  (train_test.kitch_sq == 1))\n",
    "isbad_kitch_sq_id = train_test.loc[isbad_kitch_sq, 'id']\n",
    "train_test.loc[isbad_kitch_sq, 'kitch_sq'] = np.NaN\n",
    "print 'bad_kitch_sq', np.sum(isbad_kitch_sq)\n",
    "\n",
    "# @build_year\n",
    "isbad_build_year = ((train_test.build_year < 1500) |\n",
    "                    (train_test.build_year > 2200))\n",
    "isbad_build_year_id = train_test.loc[isbad_build_year, 'id']\n",
    "train_test.loc[isbad_build_year, 'build_year'] = np.NaN\n",
    "print 'bad_build_year', np.sum(isbad_build_year)\n",
    "\n",
    "# @num_room\n",
    "isbad_num_room_selected_id = train_test.iloc[[10076, 11621, 17764, 19390, 24007, 26713, 29172, 3174, 7313]].id.unique()\n",
    "isbad_num_room = ((train_test.id.isin(isbad_num_room_selected_id)) |\n",
    "                  (train_test.num_room == 0))\n",
    "isbad_num_room_id = train_test.loc[isbad_num_room, 'id']\n",
    "train_test.loc[isbad_num_room, 'num_room'] = np.NaN\n",
    "print 'bad_num_room', np.sum(isbad_num_room)\n",
    "\n",
    "# @floor\n",
    "isbad_floor = ((train_test.floor > train_test.max_floor)|\n",
    "               (train_test.floor == 0))\n",
    "isbad_floor_id = train_test.loc[isbad_floor, 'id']\n",
    "train_test.loc[isbad_floor, 'num_room'] = np.NaN\n",
    "print 'bad_floor', np.sum(isbad_floor)\n",
    "\n",
    "# @max_floor\n",
    "isbad_max_floor = ((train_test.floor > train_test.max_floor)|\n",
    "                   (train_test.max_floor == 0))\n",
    "isbad_max_floor_id = train_test.loc[isbad_max_floor, 'id']\n",
    "train_test.loc[isbad_max_floor, 'num_room'] = np.NaN\n",
    "print 'max_floor', np.sum(isbad_max_floor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_clean & train_ex (target outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_outlier 41\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train = train_test.loc[train_test.id.isin(train_id.unique())]\n",
    "test = train_test.loc[train_test.id.isin(test_id.unique())]\n",
    "\n",
    "train_outlier = ((train.price_doc/train.full_sq > 600000) |\n",
    "                 (train.price_doc/train.full_sq < 10000))\n",
    "train_outlier_id = train.loc[train_outlier].id\n",
    "print 'train_outlier', np.sum(train_outlier)\n",
    "\n",
    "train_clean = train.loc[~train_outlier].copy()\n",
    "train_ex = train.loc[train_outlier].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_test additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add month-year\n",
    "month_year = (train.timestamp.dt.month + train.timestamp.dt.year * 100)\n",
    "month_year_cnt_map = month_year.value_counts().to_dict()\n",
    "train['month_year_cnt'] = month_year.map(month_year_cnt_map)\n",
    "\n",
    "month_year = (test.timestamp.dt.month + test.timestamp.dt.year * 100)\n",
    "month_year_cnt_map = month_year.value_counts().to_dict()\n",
    "test['month_year_cnt'] = month_year.map(month_year_cnt_map)\n",
    "\n",
    "# Add week-year count\n",
    "week_year = (train.timestamp.dt.weekofyear + train.timestamp.dt.year * 100)\n",
    "week_year_cnt_map = week_year.value_counts().to_dict()\n",
    "train['week_year_cnt'] = week_year.map(week_year_cnt_map)\n",
    "\n",
    "week_year = (test.timestamp.dt.weekofyear + test.timestamp.dt.year * 100)\n",
    "week_year_cnt_map = week_year.value_counts().to_dict()\n",
    "test['week_year_cnt'] = week_year.map(week_year_cnt_map)\n",
    "\n",
    "# Add month and day-of-week\n",
    "train['month'] = train.timestamp.dt.month\n",
    "train['dow'] = train.timestamp.dt.dayofweek\n",
    "\n",
    "test['month'] = test.timestamp.dt.month\n",
    "test['dow'] = test.timestamp.dt.dayofweek\n",
    "\n",
    "# Other feature engineering\n",
    "train['rel_floor'] = train['floor'] / train['max_floor'].astype(float)\n",
    "train['rel_kitch_sq'] = train['kitch_sq'] / train['full_sq'].astype(float)\n",
    "\n",
    "test['rel_floor'] = test['floor'] / test['max_floor'].astype(float)\n",
    "test['rel_kitch_sq'] = test['kitch_sq'] / test['full_sq'].astype(float)\n",
    "\n",
    "train.apartment_name=train.sub_area + train['metro_km_avto'].astype(str)\n",
    "test.apartment_name=test.sub_area + train['metro_km_avto'].astype(str)\n",
    "\n",
    "train['room_size'] = train['life_sq'] / train['num_room'].astype(float)\n",
    "test['room_size'] = test['life_sq'] / test['num_room'].astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess (macro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# single xgb"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "nav_menu": {
    "height": "84px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "908px",
    "left": "0px",
    "right": "708px",
    "top": "106px",
    "width": "336px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
